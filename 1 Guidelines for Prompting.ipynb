{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pautas para el prompting\n",
    "\n",
    "En esta lección, pondrá en práctica dos principios y sus tácticas relacionadas para escribir instrucciones eficaces para modelos lingüísticos de gran tamaño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. Revise el código de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"TU API KEY\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model):\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principios del prompting\n",
    "- ** Principio 1: Escribir instrucciones claras y específicas**\n",
    "- ** Principio 2: Dar tiempo al modelo para pensar**\n",
    "\n",
    "### Tácticas\n",
    "\n",
    "#### Táctica 1: Usar delimitadores para indicar claramente las distinas partes de una entrada.\n",
    "- - Los delimitadores pueden ser ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto habla sobre la importancia de dar instrucciones claras y específicas a un modelo para obtener el resultado deseado y reducir la posibilidad de recibir respuestas irrelevantes o incorrectas. Además, se destaca que escribir un mensaje claro no necesariamente implica que sea corto, ya que en algunos casos, instrucciones más largas pueden proporcionar más claridad y contexto al modelo, lo que puede conducir a resultados más detallados y relevantes.\n"
     ]
    }
   ],
   "source": [
    "# Variable: text contiene el texto que se quiere resumir \n",
    "# El código define una cadena de texto text que contiene una serie de instrucciones para guiar a un modelo y\n",
    "# reducir las posibilidades de recibir respuestas irrelevantes o incorrectas. Luego, utiliza la variable text\n",
    "# para construir una variable prompt que se utiliza para obtener una respuesta del modelo\n",
    "# (no está definido en el código proporcionado). La respuesta se imprime en la consola. La solicitud al modelo es\n",
    "# que resuma el texto que se encuentra entre las comillas triples de la variable text.\n",
    "\n",
    "text = f\"\"\"\n",
    "Debe expresar lo que quiere que haga un modelo mediante \\\n",
    "instrucciones tan claras y específicas  \\\n",
    "tan claras y específicas como sea posible. \\ \n",
    "Esto guiará al modelo hacia el resultado deseado, y reducirá las posibilidades de recibir instrucciones irrelevantes. \\\n",
    "y reducirá las posibilidades de recibir respuestas irrelevantes o incorrectas. \\\n",
    "irrelevantes o incorrectas. No confunda escribir una \\\n",
    "No confunda escribir un mensaje claro con escribir un mensaje corto. \\ \n",
    "En muchos casos, las instrucciones más largas proporcionan más claridad y contexto para el modelo, lo que puede dar lugar a respuestas más claras. \\\n",
    "y contexto para el modelo, lo que puede conducir a \\\n",
    "resultados más detallados y relevantes.\n",
    "\"\"\"\n",
    "\n",
    "#Añade al prompt la variable text para que el modelo pueda resumir el texto\n",
    "prompt = f\"\"\"\n",
    "Resume el texto delimitado por comillas triples \n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Táctica 2: Pedir un resultado estructurado\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"libro_id\": 1,\n",
      "    \"titulo\": \"El jardín de las mariposas\",\n",
      "    \"autor\": \"Ana García\",\n",
      "    \"genero\": \"Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"libro_id\": 2,\n",
      "    \"titulo\": \"La ciudad de los sueños rotos\",\n",
      "    \"autor\": \"Carlos Pérez\",\n",
      "    \"genero\": \"Novela negra\"\n",
      "  },\n",
      "  {\n",
      "    \"libro_id\": 3,\n",
      "    \"titulo\": \"El secreto de la casa del acantilado\",\n",
      "    \"autor\": \"María López\",\n",
      "    \"genero\": \"Misterio\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# El código muestra una solicitud (prompt) para que el usuario genere una lista de tres libros inventados con sus\n",
    "# autores y géneros y los proporcione en formato JSON con cuatro claves:\n",
    "# libro_id, título, autor y género.\n",
    "# Luego, utiliza una función llamada get_completion que utiliza un modelo de lenguaje para generar una respuesta.\n",
    "# Es posible que la función get_completion esté utilizando un modelo de lenguaje basado en inteligencia artificial\n",
    "# para generar una respuesta basada en la entrada de la solicitud. El resultado de la respuesta se almacena en\n",
    "# la variable response y luego se imprime.\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Genere una lista de tres títulos de libros inventados junto con sus autores y géneros. \n",
    "con sus autores y géneros pertenecientes a sus autores y generos\n",
    "Proporciónelos en formato JSON una lista con las siguientes claves:\n",
    "libro_id, titulo, autor, genero.\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Táctica 3: Pedir al modelo que compruebe si se cumplen las condiciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - Add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Este prompt contiene un texto con instrucciones para hacer una taza de té.\n",
    "# El modelo debe reescribir las instrucciones en formato de lista.\n",
    "# Si el texto no contiene instrucciones, el modelo debe escribir \"No steps provided.\"\n",
    "\n",
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado para el texto 1:\n",
      "\"No se proporcionaron los pasos\"\n"
     ]
    }
   ],
   "source": [
    "# Aqui este el codigo para el texto 2 el cual no contiene instrucciones para hacer una lista\n",
    "# El modelo debe escribir \"No steps provided.\"\n",
    "\n",
    "text_2 = f\"\"\"\n",
    "Hoy brilla el sol y los pájaros cantan. \\\n",
    "Es un bonito día para dar un paseo por el parque. \n",
    "pasear por el parque. Las flores están floreciendo, y los árboles \\ \n",
    "se mecen suavemente con la brisa.\\\n",
    "La gente disfruta del buen tiempo. \\ \n",
    "Algunos hacen picnic, otros juegan o simplemente se relajan en la hierba.\\ \n",
    "Es un día día perfecto para pasar tiempo al aire libre y apreciar la \n",
    "la belleza de la naturaleza. \\\n",
    "\"\"\" \n",
    "prompt = f\"\"\"\n",
    "Se le proporcionará un texto delimitado por comillas triples.\n",
    "Si contiene una secuencia de instrucciones,\\\n",
    "reescribalas con el siguiente formato: \n",
    "\n",
    "Paso 1 - ...\n",
    "Paso 2 - ...\n",
    "...\n",
    "Paso N - ...    \n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, \\\n",
    "entonces simplemente escriba \\ \"No se proporcionaron los pasos\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(\"Resultado para el texto 1:\")\n",
    "print(response)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Táctica 4: \"Pocos disparos prompt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<abuelo>: La resilencia es como un árbol que se dobla con el viento, pero no se quiebra. Es la capacidad de adaptarse y superar las adversidades, de encontrar la fuerza interior para seguir adelante cuando todo parece perdido. La resilencia se cultiva con la perseverancia y la confianza en uno mismo, y nos permite enfrentar los desafíos de la vida con valentía y determinación.\n"
     ]
    }
   ],
   "source": [
    "# Este código es una muestra de cómo se podría utilizar un modelo de lenguaje con habilidades de generación de texto\n",
    "# automático para crear una respuesta coherente y cohesiva a partir de un prompt dado.\n",
    "# Primero, se define una variable 'prompt' como una cadena de texto que contiene una conversación ficticia entre un\n",
    "# niño y un abuelo. La conversación trata sobre enseñar al niño sobre la paciencia y la resiliencia.\n",
    "\n",
    "# Luego, se utiliza la función 'get_completion' (que muy probablemente es una función personalizada para llamar al\n",
    "# modelo pre-entrenado) para generar una respuesta continuación a partir del prompt dado.\n",
    "\n",
    "# Por último, la respuesta generada se asigna a la variable 'response' y se imprime en pantalla mediante la función\n",
    "# 'print'.\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Tu tarea es responder con un estilo coherente.\n",
    "\n",
    "<niño>: Enséñame sobre la paciencia\n",
    "\n",
    "<abuelo>: El río que esculpe el más profundo valle fluye de un modesto manantial. \\\n",
    "la sinfonia más grandiosa sinfonía se origina en una sola nota; \\ \n",
    "el tapiz más intrincado comienza con un hilo solitario. \\\n",
    "\n",
    "<niño>: Enséñame sobre la resilencia\n",
    "\"\"\" \n",
    "\n",
    "response = get_completion(prompt,model)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<abuelo>: La resilencia es como un árbol que se dobla con el viento, pero no se quiebra. Es la capacidad de adaptarse y superar las adversidades, de encontrar la fuerza interior para seguir adelante cuando todo parece perdido. La resilencia se cultiva con la perseverancia y la confianza en uno mismo, y nos permite enfrentar los desafíos de la vida con valentía y determinación.\n"
     ]
    }
   ],
   "source": [
    "# El código está creando un prompt en formato string para pedir al modelo de lenguaje que genere una respuesta.\n",
    "# En el prompt se le pide al modelo que enseñe sobre la paciencia a un niño y el abuelo da una respuesta reflexiva.\n",
    "# Luego se pide al modelo que enseñe sobre la resiliencia a ese mismo niño.\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Tu tarea es responder con un estilo coherente.\n",
    "\n",
    "<niño>: Enséñame sobre la paciencia\n",
    "\n",
    "<abuelo>: El río que esculpe el más profundo valle fluye de un modesto manantial. \\\n",
    "la sinfonia más grandiosa sinfonía se origina en una sola nota; \\ \n",
    "el tapiz más intrincado comienza con un hilo solitario. \\\n",
    "\n",
    "<niño>: Enséñame sobre la resilencia\n",
    "\"\"\" \n",
    "\n",
    "response = get_completion(prompt,model)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principio 2: Dar tiempo al modelo para pensar\n",
    "\n",
    "#### Táctica 1: Especificar los pasos requeridos para completar una tarea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado para el texto 1:\n",
      "1 - Dos hermanos, Jack y Jill, van en busca de agua a un pozo en la cima de una colina. Mientras suben, cantando alegremente, ocurre un accidente: Jack tropieza con una piedra y rueda colina abajo, seguido por Jill. A pesar de las heridas, regresan a casa y son consolados. A pesar del percance, su espíritu aventurero sigue intacto y continúan explorando con alegría.\n",
      "\n",
      "2 - En un encantador pueblo, los hermanos Jack y Jill se embarcan en una búsqueda para traer agua de un pozo en la cima de una colina. Mientras subían, cantando alegremente, la desgracia los golpeó: Jack tropezó con una piedra y rodó colina abajo, seguido por Jill. Aunque un poco magullados, los dos regresaron a casa para ser consolados. A pesar del percance, su espíritu aventurero no se desvaneció y continuaron explorando con alegría.\n",
      "\n",
      "3 - Jack, Jill\n",
      "\n",
      "4 - {\n",
      "      \"resumen_español\": \"En un encantador pueblo, los hermanos Jack y Jill se embarcan en una búsqueda para traer agua de un pozo en la cima de una colina. Mientras subían, cantando alegremente, la desgracia los golpeó: Jack tropezó con una piedra y rodó colina abajo, seguido por Jill. Aunque un poco magullados, los dos regresaron a casa para ser consolados. A pesar del percance, su espíritu aventurero no se desvaneció y continuaron explorando con alegría.\",\n",
      "      \"num_nombres\": 2\n",
      "   }\n"
     ]
    }
   ],
   "source": [
    "# El código define una variable 'text' que contiene un string multilinea que narra una historia sobre dos hermanos,\n",
    "# Jack y Jill. Luego se utiliza la variable 'text' en un ejemplo de una solicitud a un modelo de lenguaje natural\n",
    "# para generar una respuesta.\n",
    "\n",
    "# La solicitud al modelo de lenguaje natural pide lo siguiente:\n",
    "\n",
    "#   - Resumir el texto delimitado por triples comillas.\n",
    "#   - Traducir el texto resumido al español.\n",
    "#   - Listar cada nombre incluido en el resumen en español.\n",
    "#   - Mostrar un objeto json que contenga las siguientes claves: 'resumen_español', 'num_nombres'.\n",
    "\n",
    "# El resultado de la solicitud se almacena en la variable 'response'.\n",
    "\n",
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "# Ejemplo 1\n",
    "\n",
    "prompt_1 = f\"\"\"\n",
    "Realice las siguientes acciones:\n",
    "1 - Resuma el texto delimitado por triples comillas\n",
    "2 - Traduzca el texto al español.\n",
    "3 - Lista cada nombre en el resumen en español.\n",
    "4 - Muestra un objeto json que contenga las siguientes claves: \\\n",
    "resumen_español, num_nombres.\n",
    "\n",
    "Separa tus respuestas por saltos de linea.\n",
    "\n",
    "Texto:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1,model)\n",
    "print(\"Resultado para el texto 1:\")\n",
    "print(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedir una salida en un formato específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado para el texto 2:\n",
      "Resumen: Jack y Jill van en busca de agua a un pozo en la cima de una colina, pero sufren un accidente al tropezar Jack con una piedra y caer rodando por la colina, seguido por Jill. A pesar del percance, regresan a casa y siguen explorando con alegría.\n",
      "Traducción: En un encantador pueblo, los hermanos Jack y Jill se embarcan en una búsqueda para obtener agua de un pozo en la cima de una colina. Mientras subían, cantando alegremente, la desgracia los golpeó: Jack tropezó con una piedra y rodó por la colina, seguido por Jill. Aunque un poco magullados, los dos regresaron a casa para recibir abrazos reconfortantes. A pesar del percance, sus espíritus aventureros permanecieron intactos y continuaron explorando con deleite.\n",
      "Nombres: Jack, Jill\n",
      "Salida JSON: {\"resumen_español\": \"Jack y Jill van en busca de agua a un pozo en la cima de una colina, pero sufren un accidente al tropezar Jack con una piedra y caer rodando por la colina, seguido por Jill. A pesar del percance, regresan a casa y siguen explorando con alegría.\", \"num_nombres\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Tu tarea es la son las siguientes acciones:\n",
    "1 - Resuma el texto delimitado por <> en una frase.\n",
    "2 - Traduzca el texto al español.\n",
    "3 - Lista cada nombre en el resumen en español.\n",
    "4 - Muestra un objeto json que contenga las siguientes claves: resumen_español, num_nombres.\n",
    "\n",
    "Usa el siguiente formato:\n",
    "Texto: <Texto a resumir>\n",
    "Resumen: <Resumen del texto>\n",
    "Traduccion: <Texto traducido>\n",
    "Nombres: <Lista de nombres en el resumen>\n",
    "Salida JSON: <Objeto JSON con las claves resumen_español, num_nombres>\n",
    "\n",
    "Texto: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2,model)\n",
    "print(\"Resultado para el texto 2:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Táctica 2: Pedir al modelo que elabore su propia solución antes de llegar a una conclusión precipitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La solución del estudiante es correcta. El coste total del primer año de funcionamiento de la instalación en función del número de metros cuadrados es de 450x + 100000.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determinar si la solución del estudiante es correcta o no.\n",
    "\n",
    "Pregunta:\n",
    "Estoy costruyendo una instalación de energía y necesito ayuda con las finanzas. \\\n",
    "- El terreno cuesta 100€ por metro cuadrado. \\\n",
    "- Puedo comprar paneles solares por 250€ por metro cuadrado. \\\n",
    "- He negociado un contrato de mantenimiento que me costará 100000€ al año. \n",
    "  y 10€ por metro cuadrado adicionales. \\\n",
    "¿Cuál es el coste total del primer año de funcionamiento de la instalación en función del numero de metros cuadrados?.\n",
    "\n",
    "Solución del estudiante:\n",
    "Sea x el tamaño de la instalación en metros cuadrados.\n",
    "Cost:\n",
    "1. Coste del terreno 100x\n",
    "2. Coste de los paneles solares 250x\n",
    "3. Coste del contrato de mantenimiento 100000 + 10x\n",
    "Coste total: 100x + 250x + 100000 + 100x = 450x + 100000\n",
    "\n",
    "\"\"\"\n",
    "#! La solución no es correcta porque el modelo se fija en la última frase y no en el texto completo. La solución correcta es 360x + 100000, \n",
    "\n",
    "response = get_completion(prompt,model)\n",
    "print(response)\n",
    "\n",
    "#! Seguir minuto 13:50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observa que la solución del alumno no es correcta.\n",
    "#### Podemos solucionarlo indicando al modelo que elabore primero su propia solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Coste del terreno: 100€/m² * x m² = 100x€\n",
      "2. Coste de los paneles solares: 250€/m² * x m² = 250x€\n",
      "3. Coste del contrato de mantenimiento: 100000€ + 10€/m² * x m² = 100000 + 10x€\n",
      "Coste total: 100x€ + 250x€ + 100000€ + 10x€ = 360x€ + 100000€\n",
      "\n",
      "La solución del estudiante es correcta.\n",
      "\n",
      "Calificación del alumno:\n",
      "```\n",
      "correcta\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tu tarea es determinar si la solución del estudiante es correcta o no.\\\n",
    "Para resolver el problema haz lo siguiente:\n",
    "- Primero trabaja en tu propia solución.\n",
    "- Luego compara tu solución con la solución del estudiante. y evalua la solución del estudiante es correcta o no.\n",
    "No decidas si la solución del estudiante es correcta o no hasta que hayas terminado tu propia solución.\n",
    "\n",
    "Usa el siguiente formato:\n",
    "Pregunta:\n",
    "```\n",
    "pregunta aquí\n",
    "```\n",
    "\n",
    "solución del estudiante:\n",
    "```\n",
    "solución del estudiante aquí\n",
    "```\t\n",
    "solución actual:\n",
    "```\n",
    "Usa los pasos para elaborar tu solución aquí\n",
    "```\n",
    "Es la solución del alumno igual que la actual que acabas de calcular:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Calificación del alumno:\n",
    "```\n",
    "correcta or incorrecta\n",
    "```\n",
    "\n",
    "Pregunta:\n",
    "Estoy costruyendo una instalación de energía y necesito ayuda con las finanzas.\n",
    "- El terreno cuesta 100€ por metro cuadrado.\n",
    "- Puedo comprar paneles solares por 250€ por metro cuadrado. \n",
    "- He negociado un contrato de mantenimiento que me costará 100000€ al año. y 10€ por metro cuadrado adicionales. \n",
    "¿Cuál es el coste total del primer año de funcionamiento de la instalación en función del numero de metros cuadrados?.\n",
    "\n",
    "Solución del estudiante:\n",
    "Sea x el tamaño de la instalación en metros cuadrados.\n",
    "Cost:\n",
    "1. Coste del terreno 100x\n",
    "2. Coste de los paneles solares 250x\n",
    "3. Coste del contrato de mantenimiento 100000 + 10x\n",
    "Coste total: 100x + 250x + 100000 + 100x = 450x + 100000\n",
    "```\n",
    "Solución actual:\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitaciones del modelo: Alucinaciones\n",
    "- Boie no es una empresa real, el nombre del producto no es real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, como modelo de lenguaje de IA, no tengo la capacidad de proporcionar opiniones personales. Sin embargo, puedo proporcionar información sobre el producto. El AeroGlide UltraSlim es un pequeño cepillo de dientes eléctrico de la marca Boie que utiliza tecnología de vibración sónica para limpiar los dientes y las encías de manera efectiva. Es compacto y portátil, lo que lo hace ideal para viajar o para aquellos que tienen poco espacio en el baño. Además, su diseño delgado y ergonómico lo hace fácil de sostener y usar.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. Revise el código de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Dime sobre AeroGlide UltraSlim pequeño cepillo de dientes eléctrico de Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt,model)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
