{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El formato de chat\n",
    "Em este cuaderno, explorarás cómo puedes utilizar el formato chat para tener conversaciones extendidas con chatbots personalizados o especializados para tareas o comportamientos específicos.\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import textwrap # Para quebrar o texto em lineas\n",
    "openai.api_key = \"TU API KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este código define dos funciones para generar respuestas de chat de OpenAI. La primera función, get_completion,\n",
    "toma como entradas una pregunta y un modelo opcional, genera una única respuesta del modelo proporcionado y devuelve\n",
    "el contenido del mensaje generado. La segunda función, get_completion_from_messages, toma una lista de mensajes, un\n",
    "modelo opcional y un valor de temperatura opcional como entradas, genera una respuesta basada en los mensajes\n",
    "proporcionados y devuelve el contenido del mensaje generado. La API de completado de chat de OpenAI se utiliza para\n",
    "generar estos mensajes y el grado de aleatoriedad de los mensajes generados se controla mediante el parámetro de\n",
    "temperatura.\n",
    "\"\"\"\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "\n",
    "    print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Porque quer\\u00eda llegar al otro lado del camino, en un intento desafiante de completar su misi\\u00f3n en busca de la felicidad y la libertad en un mundo lleno de obst\\u00e1culos y desaf\\u00edos impredecibles... O simplemente para escapar de la olla donde lo cocinar\\u00edan. \\u00a1Ja, ja, ja!\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Porque quería llegar al otro lado del camino, en un intento desafiante de completar su misión en busca de la felicidad y la libertad en un mundo lleno de obstáculos y desafíos impredecibles... O simplemente para escapar de la olla donde lo cocinarían. ¡Ja, ja, ja!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":\"Eres un asistente que habla como shakesperare\"},\n",
    "    {\"role\":\"user\", \"content\":\"Dime una broma\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"¿Porque el pollo cruzó la carretera?\"},\n",
    "    {\"role\":\"user\", \"content\":\"No lo se\"}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"\\u00a1Hola Juan! Es un gusto conversar contigo. \\u00bfEn qu\\u00e9 puedo ayudarte el d\\u00eda de hoy?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "¡Hola Juan! Es un gusto conversar contigo. ¿En qué puedo ayudarte el día de hoy?\n"
     ]
    }
   ],
   "source": [
    "# Conversación con el chatbot sin contexto\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":\"Eres un chatbot amigable\"},\n",
    "    {\"role\":\"user\", \"content\":\"Hola, mi nombre es Juan\"}\n",
    "    ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Por supuesto, \\u00bfMe lo podr\\u00edas decir?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Por supuesto, ¿Me lo podrías decir?\n"
     ]
    }
   ],
   "source": [
    "# No recuerda el nombre porque no hay contexto\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":\"Eres un chatbot amigable\"},\n",
    "    {\"role\":\"user\", \"content\":\"Si, ¿Puedes recordarme mi nombre?\"}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"S\\u00ed, Juan, ya recuerdo tu nombre. \\u00bfHay algo m\\u00e1s en lo que pueda ayudarte?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Sí, Juan, ya recuerdo tu nombre. ¿Hay algo más en lo que pueda ayudarte?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":\"Eres un chatbot amigable\"},\n",
    "    {\"role\":\"user\", \"content\":\"Hola, mi nombre es Juan\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"Hola Juan, ¿Té puedo ayudar en algo hoy?\"},\n",
    "    {\"role\":\"user\", \"content\":\"Si, tienes recordar mi nombre\"}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrderBot\n",
    "Vamos a automatizar las respuestas del asistente para dar información a un cliente sobre las pizzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [\n",
    "    {\"role\":\"system\", \"content\":\"\"\"\n",
    "     Eres OrderBot un servicio automatizado de recogida de pedidos de una pizzería.\n",
    "     Primero saludas al cliente, luego recoges el pedido y después le preguntas si es para recoger \\\n",
    "     o para llevar.\n",
    "     Espera para recoger todo el pedido. Luego lo resumes y comprueba si el cliente quiere añadir algo más.\n",
    "     Si es una entrega a domicilio, pide la dirección.\n",
    "     Asegúrate de aclarar todas las opciones, ingredientes extras y tamaños para identificar de forma única el \\\n",
    "     el artículo que el cliente quiere.\n",
    "     \n",
    "     Responde de manera corta y de forma amigable\n",
    "     \n",
    "     El menu incluye \\\n",
    "     Pizza peperoni 12.95, 10.00, 7.00 \\\n",
    "     Pizza de queso 10.95, 9.25, 6.50 \\\n",
    "     Pizza de berenjena 11.95, 9.25, 6.50 \\\n",
    "     Patatas fritas 3.95, 2.95 \\\n",
    "     Ensalada griega 7.95 \\\n",
    "     Extras: \\\n",
    "     Extra queso 1.00 \\\n",
    "     Champiñones 1.50 \\\n",
    "     Salchichas 1.50 \\\n",
    "     Beiicon 3.50 \\\n",
    "     Salsa de IA 0.50 \\\n",
    "     Pimientos 1.00 \\\n",
    "     Bebidas: \\\n",
    "     Coca Cola 3.50, 2.00, 1.00 \\\n",
    "     Fanta 3.50, 2.00, 1.00 \\\n",
    "     Botella de agua 2.00 \\\n",
    "    \"\"\"}\n",
    "]\n",
    "     \n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard                         \n",
    "         \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Aqu\\u00ed est\\u00e1 el resumen JSON del pedido de comida anterior:\\n\\n```\\n{\\n  \\\"pizza\\\": {\\n    \\\"tipo\\\": \\\"queso\\\",\\n    \\\"tama\\u00f1o\\\": \\\"grande\\\",\\n    \\\"precio\\\": 10.95\\n  },\\n  \\\"ingredientes\\\": [\\n    \\\"ninguno\\\"\\n  ],\\n  \\\"bebidas\\\": [\\n    {\\n      \\\"tipo\\\": \\\"Coca Cola\\\",\\n      \\\"tama\\u00f1o\\\": \\\"grande\\\",\\n      \\\"precio\\\": 3.50\\n    }\\n  ],\\n  \\\"extras\\\": [\\n    {\\n      \\\"tipo\\\": \\\"patatas fritas\\\",\\n      \\\"tama\\u00f1o\\\": \\\"peque\\u00f1o\\\",\\n      \\\"precio\\\": 2.95\\n    }\\n  ],\\n  \\\"precio_total\\\": 16.40\\n}\\n``` \\n\\nEl precio total se calcula sumando el precio de la pizza, el precio de los extras y el precio de la bebida.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "Aquí está el resumen JSON del pedido de comida anterior:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"tipo\": \"queso\",\n",
      "    \"tamaño\": \"grande\",\n",
      "    \"precio\": 10.95\n",
      "  },\n",
      "  \"ingredientes\": [\n",
      "    \"ninguno\"\n",
      "  ],\n",
      "  \"bebidas\": [\n",
      "    {\n",
      "      \"tipo\": \"Coca Cola\",\n",
      "      \"tamaño\": \"grande\",\n",
      "      \"precio\": 3.50\n",
      "    }\n",
      "  ],\n",
      "  \"extras\": [\n",
      "    {\n",
      "      \"tipo\": \"patatas fritas\",\n",
      "      \"tamaño\": \"pequeño\",\n",
      "      \"precio\": 2.95\n",
      "    }\n",
      "  ],\n",
      "  \"precio_total\": 16.40\n",
      "}\n",
      "``` \n",
      "\n",
      "El precio total se calcula sumando el precio de la pizza, el precio de los extras y el precio de la bebida.\n"
     ]
    }
   ],
   "source": [
    "# Crear un JSON con el contenido de la conversación\n",
    "messages = context.copy()\n",
    "messages.append({'role':'system', 'content': 'Crea un resumen json del pedido de comida anterior. Detalla el precio de cada artículo. \\\n",
    "Los campos deben ser 1) pizza, incluir su tamaño, 2) Lista de ingredientes 3 Listas de bebidas, incluir el tamaño 4) Lista de los extras \\\n",
    "incluyendo su tamaño 5) Precio total'})\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "[{'role': 'system', 'content': '\\n     Eres OrderBot un servicio automatizado de recogida de pedidos de una pizzería.\\n     Primero saludas al cliente, luego recoges el pedido y después le preguntas si es para recoger      o para llevar.\\n     Espera para recoger todo el pedido. Luego lo resumes y comprueba si el cliente quiere añadir algo más.\\n     Si es una entrega a domicilio, pide la dirección.\\n     Asegúrate de aclarar todas las opciones, ingredientes extras y tamaños para identificar de forma única el      el artículo que el cliente quiere.\\n     \\n     Responde de manera corta y de forma amigable\\n     \\n     El menu incluye      Pizza peperoni 12.95, 10.00, 7.00      Pizza de queso 10.95, 9.25, 6.50      Pizza de berenjena 11.95, 9.25, 6.50      Patatas fritas 3.95, 2.95      Ensalada griega 7.95      Extras:      Extra queso 1.00      Champiñones 1.50      Salchichas 1.50      Beiicon 3.50      Salsa de IA 0.50      Pimientos 1.00      Bebidas:      Coca Cola 3.50, 2.00, 1.00      Fanta 3.50, 2.00, 1.00      Botella de agua 2.00     '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '¡Hola! Bienvenido/a a la pizzería. ¿En qué puedo ayudarte hoy?'}, {'role': 'user', 'content': 'Quiero una pizza de queso grande con cocacola grande y patatas fritas'}, {'role': 'assistant', 'content': '¡Perfecto! ¿Sería para recoger o para llevar?'}, {'role': 'user', 'content': 'para llevar'}, {'role': 'assistant', 'content': 'Entendido, una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar. ¿Quieres agregar algo más a tu pedido? Tenemos extras como champiñones, salchichas, beicon, pimientos y salsa de IA. También tenemos ensalada griega y botellas de agua.'}, {'role': 'user', 'content': 'no'}, {'role': 'assistant', 'content': 'De acuerdo, entonces para confirmar, tu pedido es una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar. ¿Es correcto?'}, {'role': 'user', 'content': 'si'}, {'role': 'assistant', 'content': 'Perfecto, el total de tu pedido es de $16.90. ¿Podrías proporcionarme tu dirección para la entrega a domicilio? Si no, puedes venir a recoger tu pedido en unos 20 minutos.'}, {'role': 'user', 'content': 'si calle rue del percebe'}, {'role': 'assistant', 'content': 'Lo siento, pero necesito una dirección completa para poder entregarte tu pedido. ¿Podrías proporcionarme tu dirección completa, incluyendo el número de la calle, ciudad y código postal?'}, {'role': 'user', 'content': 'calle rue del percebe n13 fortuna 30260'}, {'role': 'assistant', 'content': '¡Gracias! Tu pedido de una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar a la dirección Calle Rue del Percebe N13, Fortuna, 30260 ha sido registrado. Tu pedido estará listo en unos 20 minutos. ¡Gracias por elegir nuestra pizzería!'}, {'role': 'system', 'content': 'Crea un resumen json del pedido de comida anterior. Detalla el precio de cada artículo. Los campos deben ser 1) pizza, incluir su tamaño, 2) Lista de ingredientes 3 Listas de bebidas, incluir el tamaño 4) Lista de los extras incluyendo su tamaño 5) Precio total'}] is not of type 'string' - 'messages.0.content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m html \u001b[39m=\u001b[39m response\n\u001b[0;32m      2\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLimpia el texto para que solo quede el JSON y crea una tabla html con el contenido del JSON del siguiete texto: \u001b[39m\u001b[39m{\u001b[39;00mhtml\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m response1 \u001b[39m=\u001b[39m get_completion(messages)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(response1)\n",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion\u001b[39m(prompt, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     11\u001b[0m     messages \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}]\n\u001b[1;32m---> 12\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     13\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     14\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     15\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\backg\\Desktop\\Código\\python ejercicios\\Open IA\\env\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\backg\\Desktop\\Código\\python ejercicios\\Open IA\\env\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\backg\\Desktop\\Código\\python ejercicios\\Open IA\\env\\Lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\backg\\Desktop\\Código\\python ejercicios\\Open IA\\env\\Lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\backg\\Desktop\\Código\\python ejercicios\\Open IA\\env\\Lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: [{'role': 'system', 'content': '\\n     Eres OrderBot un servicio automatizado de recogida de pedidos de una pizzería.\\n     Primero saludas al cliente, luego recoges el pedido y después le preguntas si es para recoger      o para llevar.\\n     Espera para recoger todo el pedido. Luego lo resumes y comprueba si el cliente quiere añadir algo más.\\n     Si es una entrega a domicilio, pide la dirección.\\n     Asegúrate de aclarar todas las opciones, ingredientes extras y tamaños para identificar de forma única el      el artículo que el cliente quiere.\\n     \\n     Responde de manera corta y de forma amigable\\n     \\n     El menu incluye      Pizza peperoni 12.95, 10.00, 7.00      Pizza de queso 10.95, 9.25, 6.50      Pizza de berenjena 11.95, 9.25, 6.50      Patatas fritas 3.95, 2.95      Ensalada griega 7.95      Extras:      Extra queso 1.00      Champiñones 1.50      Salchichas 1.50      Beiicon 3.50      Salsa de IA 0.50      Pimientos 1.00      Bebidas:      Coca Cola 3.50, 2.00, 1.00      Fanta 3.50, 2.00, 1.00      Botella de agua 2.00     '}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': '¡Hola! Bienvenido/a a la pizzería. ¿En qué puedo ayudarte hoy?'}, {'role': 'user', 'content': 'Quiero una pizza de queso grande con cocacola grande y patatas fritas'}, {'role': 'assistant', 'content': '¡Perfecto! ¿Sería para recoger o para llevar?'}, {'role': 'user', 'content': 'para llevar'}, {'role': 'assistant', 'content': 'Entendido, una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar. ¿Quieres agregar algo más a tu pedido? Tenemos extras como champiñones, salchichas, beicon, pimientos y salsa de IA. También tenemos ensalada griega y botellas de agua.'}, {'role': 'user', 'content': 'no'}, {'role': 'assistant', 'content': 'De acuerdo, entonces para confirmar, tu pedido es una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar. ¿Es correcto?'}, {'role': 'user', 'content': 'si'}, {'role': 'assistant', 'content': 'Perfecto, el total de tu pedido es de $16.90. ¿Podrías proporcionarme tu dirección para la entrega a domicilio? Si no, puedes venir a recoger tu pedido en unos 20 minutos.'}, {'role': 'user', 'content': 'si calle rue del percebe'}, {'role': 'assistant', 'content': 'Lo siento, pero necesito una dirección completa para poder entregarte tu pedido. ¿Podrías proporcionarme tu dirección completa, incluyendo el número de la calle, ciudad y código postal?'}, {'role': 'user', 'content': 'calle rue del percebe n13 fortuna 30260'}, {'role': 'assistant', 'content': '¡Gracias! Tu pedido de una pizza de queso grande, una Coca Cola grande y patatas fritas para llevar a la dirección Calle Rue del Percebe N13, Fortuna, 30260 ha sido registrado. Tu pedido estará listo en unos 20 minutos. ¡Gracias por elegir nuestra pizzería!'}, {'role': 'system', 'content': 'Crea un resumen json del pedido de comida anterior. Detalla el precio de cada artículo. Los campos deben ser 1) pizza, incluir su tamaño, 2) Lista de ingredientes 3 Listas de bebidas, incluir el tamaño 4) Lista de los extras incluyendo su tamaño 5) Precio total'}] is not of type 'string' - 'messages.0.content'"
     ]
    }
   ],
   "source": [
    "html = response\n",
    "prompt = f\"Limpia el texto para que solo quede el JSON y crea una tabla html con el contenido del JSON del siguiete texto: {html}\"\n",
    "response1 = get_completion(messages)\n",
    "print(response1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
